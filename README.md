# ANSE ‚Äî Agent Nervous System Engine

![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)
![Tests Passing](https://img.shields.io/badge/tests-passing-brightgreen.svg)
![License MIT](https://img.shields.io/badge/license-MIT-blue.svg)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)

> **Build autonomous agents that use cameras, microphones, and custom tools.**

ANSE is a local runtime engine for building autonomous agents with sensor access and tool calling. Instead of manually wiring sensor drivers and agent logic, define your tools once and agents discover + use them autonomously.

**[Project Status](#-project-status) | [Folder Map](#-folder-overview) | [Docs](#-documentation-map) | [Quick Start](#quick-start) | [Architecture](#architecture)**

---

## üîÑ Project Status

**ANSE is in active development** ‚Äî the architecture is stable, but components are being reorganized for clarity.

| Component | Status | Notes |
|-----------|--------|-------|
| **Core Engine** | ‚úÖ Stable | Engine core, world model, scheduler, tool registry, audit logging all working |
| **Event-Driven Architecture** | ‚úÖ Complete | Refactored from polling to nervous system model; fully async/await |
| **Plugin System** | üîÑ Reorganizing | Plugin code is complete; being categorized into sensors/actuators/cognition/system |
| **Documentation Suite** | ‚úÖ Complete | 6 new guides (2,123 lines) covering event-driven patterns, troubleshooting, migration |
| **Backend (WebSocket)** | ‚úÖ Complete | Pure event server with dashboard support; production-ready |
| **Dashboard** | ‚úÖ Complete | Real-time UI with 5 panels (sensor, actuator, world model, reflex, event log) |
| **Examples** | ‚è≥ Coming Soon | Examples folder created; full tutorial code coming next |
| **Tests** | ‚úÖ Complete | Unit tests passing; integration tests in place |

**What's ready to use:** Core engine, world model, tool system, audit logging, plugin registration, safety/permissions  
**What's being refined:** Dashboard UI, plugin examples, documentation guides (those are written, not code)  
**What's coming next:** Example agents, dashboard completion, performance optimization

---

## What Is ANSE?

ANSE is an open-source **local agent engine** providing:

- **üì∏ Camera tools** ‚Äî capture frames, analyze edges/corners/colors
- **üé§ Audio tools** ‚Äî record audio, analyze frequencies and amplitude
- **üîä TTS tools** ‚Äî text-to-speech with multiple voices
- **üîå Plugin system** ‚Äî add custom sensors via YAML or Python
- **üîí Safety** ‚Äî rate limiting, permission scopes, audit logging
- **‚ôªÔ∏è Simulation mode** ‚Äî deterministic offline testing without hardware
- **üéõÔ∏è Operator UI** ‚Äî web dashboard for monitoring + approvals
- **üìù Audit trail** ‚Äî immutable event logs with SHA256 hashing

**Build with ANSE if you need:**
- Agents that capture real sensor data and respond autonomously
- Consistent APIs for testing with simulated sensors and deploying with real hardware
- On-device autonomous systems without cloud dependencies
- Tool discovery and autonomous tool use
- Complete audit trails and reproducibility

---

## Quick Start

### Install

```bash
git clone https://github.com/13thrule/ANSE-Agent-Nervous-System-Engine
cd ANSE-Agent-Nervous-System-Engine
pip install -r requirements.txt
```

### Run the Demo (30 seconds)

**Terminal 1 ‚Äî Start the engine:**
```bash
python -m anse.engine_core
```

**Terminal 2 ‚Äî Run an autonomous agent:**
```bash
# With real hardware (camera/mic required)
python agent_demo.py

# Or with simulated hardware (no hardware needed)
ANSE_SIMULATE=1 python agent_demo.py
```

**What happens:**
- Agent discovers available tools
- Captures a frame from camera (or simulated)
- Analyzes the frame (edge/corner detection, color histogram)
- Records audio from microphone (or simulated)
- Analyzes audio (frequency spectrum, RMS, peak amplitude)
- Speaks a result using text-to-speech
- Logs everything to audit trail

---

## üé® Visual Dashboard ‚Äî Real-Time Nervous System Monitoring

ANSE includes a **production-ready web dashboard** that streams real-time events from the nervous system.

### See It In Action

![ANSE Demo GUI - Complete nervous system visualization with event streaming](docs/screenshots/01-full-dashboard.png)

### Dashboard Features

**5 Real-Time Panels:**
- **Sensor Panel** ‚Äî Distance sensor readings (50cm ‚Üí 5cm ‚Üí 50cm cycle)
- **Actuator Panel** ‚Äî Motor state (IDLE, STOPPED, MOVING)
- **World Model Panel** ‚Äî Brain's interpretation of the world
- **Reflex Panel** ‚Äî Safety rules triggered (proximity_safeguard, clear_to_move)
- **Event Log** ‚Äî Complete chronological stream of all events

![Real-time event log streaming sensor, reflex, and actuator events](docs/screenshots/02-event-log-detail.png)

### Run the Dashboard (30 seconds)

**Terminal 1 ‚Äî Start WebSocket Backend:**
```bash
python backend/websocket_backend.py
```

You'll see:
```
‚úì ANSE Engine initialized
‚úì World Model ready
‚úì WebSocket server running on ws://localhost:8001
Waiting for connections...
```

**Terminal 2 ‚Äî Start Dashboard HTTP Server:**
```bash
cd dashboard && python -m http.server 8002
```

You'll see:
```
Serving HTTP on 0.0.0.0 port 8002 (http://0.0.0.0:8002/) ...
```

**Browser:** Open `http://localhost:8002/` and watch the panels update with live events!

### How It Works

The dashboard demonstrates ANSE's **event-driven nervous system**:

```
Nervous System Flow:
1. SENSOR        ‚Üí Distance sensor emits readings every 1.5s
2. WORLD MODEL   ‚Üí Brain records and interprets readings (safe/danger)
3. REFLEX PHASE  ‚Üí Check conditions (distance < 10cm?)
4. ACTUATOR      ‚Üí Execute action (STOP or MOVE)
5. BROADCAST     ‚Üí Send events to all WebSocket clients (Dashboard)
6. DASHBOARD     ‚Üí Panels update in real-time

All 5 phases complete in ~150ms, fully event-driven, zero polling.
```

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ WebSocket Backend (port 8001)                   ‚îÇ
‚îÇ ‚Ä¢ ANSE EngineCore (nervous system sim)          ‚îÇ
‚îÇ ‚Ä¢ Sensor ‚Üí Reflex ‚Üí Actuator cycle              ‚îÇ
‚îÇ ‚Ä¢ Broadcasts events via WebSocket               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ ws:// (real-time events)
                  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Dashboard (port 8002)                           ‚îÇ
‚îÇ ‚Ä¢ Pure HTML/CSS/JavaScript (zero dependencies)  ‚îÇ
‚îÇ ‚Ä¢ 5 panel types (sensor, actuator, reflex, etc) ‚îÇ
‚îÇ ‚Ä¢ Real-time event streaming                     ‚îÇ
‚îÇ ‚Ä¢ Event log with chronological history          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç What's Working vs. What's In Progress

**‚úÖ Fully Functional & Stable:**
- Core engine (world model, scheduler, tool registry)
- Event-driven nervous system (async/await, event streaming)
- Plugin system (YAML and Python plugins)
- Sensor tools (camera, audio, TTS with analysis)
- Simulated tools (deterministic testing without hardware)
- Safety & permissions system (scopes, rate limiting, audit logs)
- Audit trail (immutable JSONL, SHA256 hashing)
- Operator UI (Flask admin dashboard)
- **Production WebSocket backend** (pure event server, 280 lines)
- **Real-time dashboard** (HTML/CSS/JS, 15 files, zero dependencies, 5 panel types)
- **Complete documentation** (7 guides, screenshots, quick-start)
- Tests (unit and integration tests passing)

**üîÑ In Progress:**
- Extended example library (structure in place)
- Additional sensor/actuator templates

**‚è≥ Coming Next:**
- Performance optimization & benchmarking
- Network tools (HTTP, DNS, ping)
- Filesystem tools (sandboxed safe access)
- Browser automation tools

---

## ÔøΩ Recent Improvements (Feb 2026)

### Production Backend & Dashboard

**What Changed:**
- Extracted pure WebSocket backend from demo code ‚Üí `/backend/websocket_backend.py` (280 lines, production-ready)
- Created production dashboard ‚Üí `/dashboard/` (15 files, 7,600+ lines, zero dependencies)
- Clean architecture separation: Backend (events) | Dashboard (UI) | Demo (reference)

**Why It Matters:**
- Backend can run independently on edge devices or IoT hardware
- Dashboard is pure vanilla HTML/CSS/JS (no node_modules, no build tools)
- Easy to deploy, test, and customize

**What You Get:**
- Real-time nervous system visualization (5 panel types)
- WebSocket event streaming with automatic client reconnection
- Production-ready error handling and logging
- Comprehensive deployment guides (Docker, systemd, Nginx)

**Documentation:**
- `QUICK_START.md` ‚Äî Get running in 30 seconds
- `BACKEND_REFACTORING_COMPLETE.md` ‚Äî Architecture deep-dive
- `backend/README.md` ‚Äî Complete API and deployment guide
- See screenshots above ‚¨ÜÔ∏è

---

## üìÇ Folder Overview

Here's what each folder contains and its maturity level:

### Core System
| Folder | Purpose | Maturity |
|--------|---------|----------|
| **[anse/](anse/)** | Core engine, world model, scheduler, async runtime | ‚úÖ Stable |
| **[tests/](tests/)** | Unit and integration tests | ‚úÖ Stable |
| **[operator_ui/](operator_ui/)** | Flask admin dashboard, approvals, audit logs | ‚úÖ Stable |

### Plugins (Organized by Role)
| Folder | Purpose | Maturity |
|--------|---------|----------|
| **[plugins/sensors/](plugins/sensors/)** | Sensor templates + examples (Arduino, Modbus, Hue, etc.) | ‚úÖ Complete |
| **[plugins/actuators/](plugins/actuators/)** | Motor control and actuator interfaces | ‚úÖ Complete |
| **[plugins/cognition/](plugins/cognition/)** | Body schema, long-term memory, reward system | ‚úÖ Complete |
| **[plugins/system/](plugins/system/)** | Reflex system, dashboard bridge, infrastructure | ‚úÖ Complete |

### UI & Presentation
| Folder | Purpose | Maturity |
|--------|---------|----------|
| **[dashboard/](dashboard/)** | Production web dashboard (HTML/CSS/JS) ‚Äî real-time event panels | ‚úÖ Complete |
| **[backend/](backend/)** | Pure WebSocket server for dashboard backend ‚Äî production deployment ready | ‚úÖ Complete |
| **[examples/gui_demo/](examples/gui_demo/)** | Reference demo implementation | ‚úÖ Reference |

### Documentation
| Folder | Purpose | Maturity |
|--------|---------|----------|
| **[docs/](docs/)** | All guides, references, API docs (21 files) | ‚úÖ Complete |
| **[docs/screenshots/](docs/screenshots/)** | Dashboard screenshots and visual guide | ‚úÖ Complete |
| **[scripts/](scripts/)** | Utility scripts for setup, debug, deploy | ‚è≥ Coming Soon |

---

## üìö Documentation Map

ANSE has six comprehensive event-driven architecture guides. **Here's when to use each:**

### üöÄ **Just Starting?**
1. **[QUICKSTART.md](docs/QUICKSTART.md)** (5 min read)
   - Install and run the demo
   - See your first agent in action
   - Tests passing? You're good to go.
2. **[QUICK_START.md](QUICK_START.md)** (5 min read) ‚Äî **NEW!**
   - Run the production dashboard
   - Real-time nervous system visualization
   - See all 5 panels updating with live events

3. **[EVENT_DRIVEN_ARCHITECTURE.md](docs/EVENT_DRIVEN_ARCHITECTURE.md)** (15 min read)
   - How ANSE works as a nervous system
   - Event flow, world model, reflexes, agents
   - Core principles and patterns

### üé® **Want to See It In Action?**
- **[Dashboard Guide](SCREENSHOTS.md)** ‚Äî Visual walkthrough with screenshots
- **[Backend API](backend/README.md)** ‚Äî WebSocket backend configuration and deployment
- **[Architecture Refactoring](BACKEND_REFACTORING_COMPLETE.md)** ‚Äî How we separated backend/dashboard/demo

### üîß **Building Something?**
4. **[IMPLEMENTATION_CHECKLIST.md](docs/IMPLEMENTATION_CHECKLIST.md)** (step-by-step guide)
   - Structured 6-phase approach (10-20 days)
   - Build agents, sensors, actuators step-by-step
   - Includes code templates and testing strategies

5. **[EVENT_DRIVEN_CHEATSHEET.md](docs/EVENT_DRIVEN_CHEATSHEET.md)** (quick reference)
   - 5-minute patterns you'll use constantly
   - Copy-paste ready code examples
   - Do's and don'ts

### üîÑ **Migrating Existing Code?**
6. **[MIGRATION_POLLING_TO_EVENTS.md](docs/MIGRATION_POLLING_TO_EVENTS.md)** (practical guide)
   - Convert polling loops to event listeners
   - Before/after code examples
   - Performance gains (25x latency, 82% CPU reduction)

### üõ†Ô∏è **Debugging Issues?**
7. **[TROUBLESHOOTING_EVENT_DRIVEN.md](docs/TROUBLESHOOTING_EVENT_DRIVEN.md)** (problem solver)
   - 5 major problem categories with solutions
   - Debugging checklist (8 steps)
   - Hardware polling detection methods

### üìñ **Other Resources**
- **[DESIGN.md](docs/DESIGN.md)** ‚Äî Architecture deep-dive (system components, async patterns)
- **[API.md](docs/API.md)** ‚Äî Complete API reference
- **[PLUGINS.md](docs/PLUGINS.md)** ‚Äî Building custom sensors and tools

---

## Repository Guide

**New to ANSE?** Start here to navigate the repo:

| Folder | Purpose |
|--------|---------|
| **[anse/](anse/)** | Core engine: world model, scheduler, tool registry, plugins |
| **[plugins/](plugins/)** | Sensor, actuator, cognition, and system plugins organized by category |
| **[backend/](backend/)** | WebSocket server for dashboard ‚Äî pure event broadcaster |
| **[dashboard/](dashboard/)** | Production web dashboard ‚Äî real-time nervous system visualization |
| **[examples/](examples/)** | Example implementations and tutorial code |
| **[docs/](docs/)** | Complete documentation: guides, references, troubleshooting |
| **[operator_ui/](operator_ui/)** | Flask admin dashboard for approvals and audit logs |
| **[tests/](tests/)** | Unit and integration tests |
| **[scripts/](scripts/)** | Utility scripts (setup, deployment, debugging) |

**Quick Navigation:**
- üöÄ [Quick Start](#quick-start) ‚Äî Get running in 30 seconds
- üìä [Dashboard](QUICK_START.md) ‚Äî Real-time event visualization
- üìö [Event-Driven Architecture](docs/EVENT_DRIVEN_ARCHITECTURE.md) ‚Äî How ANSE works
- üîß [Backend Setup](backend/README.md) ‚Äî Production deployment
- üëÄ [Screenshots Guide](SCREENSHOTS.md) ‚Äî Visual walkthrough

---

## The Nervous System Model

ANSE implements an event-driven nervous system where sensors emit events, reflexes react instantly, agents make decisions based on the world model, and all actions are audited. No polling loops. No continuous checks. All behavior flows through the immutable world model event log.

---

## Plugin System (Extensible & Powerful)

ANSE's **plugin system is the core extensibility story** ‚Äî add custom sensors without modifying the engine:

- **YAML Plugins:** Drop a config file in `plugins/` ‚Üí agent discovers it automatically (perfect for non-programmers)
- **Python Plugins:** Async plugin classes with full type hints for complex integrations  
- **Auto-Registration:** Tools appear in `list_tools()` immediately after restart  
- **Same API:** Plugins use identical interface as built-in tools

**Include example plugins for:**
- Philips Hue smart lights
- Arduino robot arms  
- Industrial Modbus PLC  
- Custom temperature sensors  

See [Plugin System Details](#plugin-system) below and [docs/PLUGINS.md](docs/PLUGINS.md) for complete guide.

---

## Built-In Tools

### Hardware Tools

| Tool | Purpose |
|------|---------|
| `capture_frame()` | Capture RGB frame from camera (640√ó480) |
| `list_cameras()` | List available camera devices |
| `analyze_frame(frame_id, frame_path)` | Edge/corner detection, color histogram |
| `record_audio(duration=2.0)` | Record audio from microphone |
| `list_audio_devices()` | List microphones and speakers |
| `analyze_audio(audio_id, audio_path)` | FFT frequency analysis, RMS, peak |
| `say(text)` | Text-to-speech synthesis |
| `get_voices()` | List available TTS voices |

### Simulated Tools (for testing without hardware)

| Tool | Purpose |
|------|---------|
| `simulate_camera()` | Generate deterministic test frames |
| `simulate_microphone()` | Generate deterministic test audio |
| Auto-selected when `ANSE_SIMULATE=1` environment variable is set |

### Plugin System

Add custom sensors and tools by creating YAML or Python files in the `plugins/` directory. See [Plugin Examples](#plugin-examples).

---

## Safety & Audit (First-Class, Not Bolted-On)

Safety is built into the engine architecture, not a separate layer:

| Feature | Implementation |
|---------|----------------|
| **Permission Scopes** | Per-agent grants (camera, mic, network, filesystem) ‚Äî deny by default |
| **Rate Limiting** | Hardware tools rate-limited (30, 10, 20 calls/min); per-agent buckets |
| **Approval Gates** | High-risk operations can require operator sign-off (built-in UI) |
| **Audit Trail** | Immutable JSONL log with SHA256 hashes ‚Äî full provenance |
| **Local Storage** | Raw media stays local; no external transmission |
| **Isolation** | Per-agent quotas prevent one agent from impacting others |

**Example:** Cap camera at 30 calls/min per agent. Agent 1 hits limit ‚Üí Agent 2 still works.

### Audit Log Format

```json
{
  "timestamp": "2026-02-14T10:30:45.123456Z",
  "agent_id": "agent-001",
  "call_id": "call-12345",
  "tool": "capture_frame",
  "args_hash": "abc123d...",
  "result_hash": "def456e...",
  "status": "success",
  "duration_ms": 145
}
```

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Agent (LLM / Script)                     ‚îÇ
‚îÇ                   Connects via WebSocket                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ JSON-RPC
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  AgentBridge (WebSocket)                    ‚îÇ
‚îÇ            handles_client() processes requests              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EngineCore                               ‚îÇ
‚îÇ  Initializes and coordinates all subsystems                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ToolRegistry  ‚îÇ  Scheduler  ‚îÇ  WorldModel  ‚îÇ  Audit Logger ‚îÇ
‚îÇ   (tool        ‚îÇ  (execute,  ‚îÇ  (append-only‚îÇ (SHA256       ‚îÇ
‚îÇ    metadata)   ‚îÇ   rate-limit‚îÇ   event log) ‚îÇ  hashing)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ     PermissionManager    ‚îÇ       Safety Policy              ‚îÇ
‚îÇ    (scopes, approval)    ‚îÇ      (YAML config)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ       Hardware Tools      ‚îÇ     Simulated Tools              ‚îÇ
‚îÇ   (video, audio, TTS)     ‚îÇ  (deterministic seeds)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Components

- **EngineCore** ‚Äî Orchestrator. Initializes scheduler, tool registry, world model, audit logger, and agent bridge. Loads plugins.
- **AgentBridge** ‚Äî WebSocket JSON-RPC server. Handles `list_tools`, `call_tool`, `get_history`, `ping` from agents.
- **ToolRegistry** ‚Äî Manages tool schemas, sensitivity labels, and execution routing. Registers built-in + plugin tools.
- **Scheduler** ‚Äî Executes tool calls with per-tool rate limiting, timeouts, and call queuing.
- **WorldModel** ‚Äî Append-only JSONL event store. Records all calls, results, timestamps. Enables replay and debugging.
- **AuditLogger** ‚Äî Cryptographically signed JSONL audit trail. SHA256 hashes of inputs/outputs for non-repudiation.
- **PermissionManager** ‚Äî Enforces YAML-based per-agent permission scopes. Deny-by-default policy.
- **PluginLoader** ‚Äî Auto-discovers and registers YAML and Python plugins from `plugins/` directory.
- **Tools** ‚Äî Async-safe implementations for hardware (video, audio, TTS) and simulated devices. All blocking I/O via `asyncio.to_thread()`.

---

## Design Principles

1. **Small, structured results** ‚Äî Return IDs and metadata, not raw data blobs
2. **Local and auditable** ‚Äî No external dependencies; full event trail on disk
3. **Agent autonomy** ‚Äî Agents decide what to do; engine enforces safety
4. **Deterministic** ‚Äî Event logs + seeded randomness enable replay and reproducibility
5. **Safe by default** ‚Äî Rate limits, permission scopes, approval gates

---

## Safety & Audit

### Built-In Features

| Feature | Details |
|---------|---------|
| **Permission Scopes** | Per-agent grants for camera, mic, network, filesystem (deny by default) |
| **Rate Limiting** | Sensible defaults (30, 10, 20 calls/min) to prevent abuse |
| **Audit Trail** | Immutable JSONL log with SHA256 hashes for provenance |
| **Local Storage** | Raw media stored locally; no external data transmission |
| **Human Approval** | High-risk operations can require operator sign-off |

### Audit Log Format

```json
{
  "timestamp": "2026-02-14T10:30:45.123456Z",
  "agent_id": "agent-001",
  "call_id": "call-12345",
  "tool": "capture_frame",
  "args_hash": "abc123d...",
  "result_hash": "def456e...",
  "status": "success",
  "duration_ms": 145,
  "error": null
}
```

---

## Examples

### Training with Simulation, Deploying with Hardware

Simulated and real tools have **identical APIs** ‚Äî develop and test offline, switch to hardware in production:

```python
from anse.engine_core import EngineCore

# Develop with simulated sensors (no hardware, deterministic, fast)
engine = EngineCore(simulate=True)
agent = MyAgent(engine)
agent.test_logic()

# Deploy with real hardware (same code, same API)
engine = EngineCore(simulate=False)
agent.run_production()
```

No code changes. Same tool calls work in both modes.

### IoT Device Control

Register custom sensors:

```bash
# Create plugins/temperature_sensor.yaml
python -m anse.engine_core
# Agent now sees and can call: temperature_sensor_read_temp()
```

### Multi-Agent System with Isolation

Run multiple agents on one engine with isolated resource quotas:

```python
engine = EngineCore()

agent1 = Agent(agent_id="robot-1", engine=engine)
agent2 = Agent(agent_id="robot-2", engine=engine)

# Each agent has its own:
# - Rate limit quota (e.g., 30 camera calls/min per agent)
# - CPU budget
# - Storage quota
# - Permission scopes (agent1 can use camera, agent2 cannot)
await asyncio.gather(agent1.run(), agent2.run())
```

---

## Operator UI

Monitor and approve agent actions via web dashboard:

```bash
cd operator_ui
pip install -r requirements.txt
python app.py
# Visit http://localhost:5000
```

**Features:**
- Live agent status dashboard
- Tool approval forms with scope controls
- Active token management
- Real-time event streaming
- Audit log viewer

---

## Plugin System

### YAML Plugins (5 minutes)

Create `plugins/my_sensor.yaml`:
```yaml
name: my_temperature_sensor
description: Custom temperature sensor
version: 0.1.0

tools:
  - name: read_temp
    description: Read current temperature in celsius
    handler: |
      return {
          'temperature': 23.5,
          'unit': 'celsius',
          'timestamp': datetime.now().isoformat()
      }
```

Restart the engine ‚Äî agent can now call `my_temperature_sensor_read_temp()`.

### Python Plugins

```python
# plugins/my_plugin.py
import asyncio
from anse.plugin import SensorPlugin

class MyPlugin(SensorPlugin):
    name = "my_plugin"
    description = "Custom plugin"
    
    async def read_sensor(self):
        """Read from custom hardware."""
        # Your implementation
        return {"status": "ok", "value": 42}
```

### Plugin Examples

```
plugins/
‚îú‚îÄ‚îÄ _template_sensor.py              # Python plugin template
‚îú‚îÄ‚îÄ _template_sensor.yaml            # YAML template
‚îú‚îÄ‚îÄ example_philips_hue.yaml         # Philips Hue smart lights
‚îú‚îÄ‚îÄ example_arduino_servo.yaml       # Arduino robot arm
‚îî‚îÄ‚îÄ example_modbus_plc.yaml          # Industrial Modbus PLC
```

See [docs/PLUGINS.md](docs/PLUGINS.md) for the complete plugin development guide.

---

## Project Structure

```
anse/                                  # Core engine
‚îú‚îÄ‚îÄ engine_core.py                    # Main orchestrator
‚îú‚îÄ‚îÄ agent_bridge.py                   # WebSocket server
‚îú‚îÄ‚îÄ tool_registry.py                  # Tool management
‚îú‚îÄ‚îÄ scheduler.py                      # Rate limiting & scheduling
‚îú‚îÄ‚îÄ world_model.py                    # Event store (JSONL)
‚îú‚îÄ‚îÄ audit.py                          # Audit logging with hashing
‚îú‚îÄ‚îÄ health.py                         # Health monitoring
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ video.py                      # Camera tools
‚îÇ   ‚îú‚îÄ‚îÄ audio.py                      # Audio tools
‚îÇ   ‚îî‚îÄ‚îÄ tts.py                        # Text-to-speech
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ event_driven_agent.py         # Reference event-driven implementation
‚îÇ   ‚îú‚îÄ‚îÄ scripted_agent.py             # Simple sequential example
‚îÇ   ‚îî‚îÄ‚îÄ llm_agent_adapter.py          # LLM integration template
‚îî‚îÄ‚îÄ safety/
    ‚îú‚îÄ‚îÄ permission.py                 # Permission enforcement
    ‚îî‚îÄ‚îÄ safety_policy.yaml            # Policy configuration

plugins/                               # Extensible plugin system
‚îú‚îÄ‚îÄ sensors/                          # Sensor plugins
‚îÇ   ‚îú‚îÄ‚îÄ _template_sensor.py           # Python template
‚îÇ   ‚îú‚îÄ‚îÄ _template_sensor.yaml         # YAML template
‚îÇ   ‚îî‚îÄ‚îÄ example_*.yaml                # Example hardware
‚îú‚îÄ‚îÄ actuators/                        # Actuator plugins (motors, controllers)
‚îÇ   ‚îî‚îÄ‚îÄ motor_control/                # Motor control interface
‚îú‚îÄ‚îÄ cognition/                        # Higher-level reasoning plugins
‚îÇ   ‚îú‚îÄ‚îÄ body_schema/                  # Spatial self-awareness
‚îÇ   ‚îú‚îÄ‚îÄ long_term_memory/             # Experience storage
‚îÇ   ‚îî‚îÄ‚îÄ reward_system/                # Learning & reinforcement
‚îî‚îÄ‚îÄ system/                           # Core system plugins
    ‚îú‚îÄ‚îÄ reflex_system/                # Fast event-driven reactions
    ‚îî‚îÄ‚îÄ dashboard_bridge/             # UI integration

examples/                              # Example applications
‚îú‚îÄ‚îÄ README.md                         # Guide to examples (coming soon)
‚îî‚îÄ‚îÄ (future: full agent examples, tutorials)

docs/                                  # Complete documentation
‚îú‚îÄ‚îÄ QUICKSTART.md                     # Getting started
‚îú‚îÄ‚îÄ EVENT_DRIVEN_ARCHITECTURE.md      # Nervous system model
‚îú‚îÄ‚îÄ EVENT_DRIVEN_CHEATSHEET.md        # Quick reference
‚îú‚îÄ‚îÄ MIGRATION_POLLING_TO_EVENTS.md    # Polling‚ÜíEvents guide
‚îú‚îÄ‚îÄ IMPLEMENTATION_CHECKLIST.md       # Step-by-step guide
‚îú‚îÄ‚îÄ TROUBLESHOOTING_EVENT_DRIVEN.md   # Problem solving
‚îú‚îÄ‚îÄ DESIGN.md                         # Architecture deep-dive
‚îú‚îÄ‚îÄ API.md                            # API reference
‚îú‚îÄ‚îÄ PLUGINS.md                        # Plugin development guide
‚îú‚îÄ‚îÄ INSTALLATION.md                   # Setup instructions
‚îî‚îÄ‚îÄ (more docs for different topics)

dashboard_ui/                          # Web monitoring dashboard
‚îú‚îÄ‚îÄ dashboard.html                    # Main interface
‚îú‚îÄ‚îÄ dashboard_client.ts               # WebSocket client
‚îú‚îÄ‚îÄ DashboardExample.svelte           # Component template
‚îî‚îÄ‚îÄ README.md                         # Status & roadmap

operator_ui/                           # Admin dashboard
‚îú‚îÄ‚îÄ app.py                            # Flask backend
‚îú‚îÄ‚îÄ models.py                         # Database models
‚îú‚îÄ‚îÄ routes/                           # API endpoints
‚îú‚îÄ‚îÄ templates/                        # HTML
‚îú‚îÄ‚îÄ static/                           # CSS/JS
‚îî‚îÄ‚îÄ requirements.txt                  # Dependencies

scripts/                               # Utility scripts
‚îú‚îÄ‚îÄ README.md                         # Script guide
‚îî‚îÄ‚îÄ (future: setup, deployment, debug tools)

tests/                                 # Unit & integration tests
‚îú‚îÄ‚îÄ test_engine_core.py
‚îú‚îÄ‚îÄ test_tools.py
‚îú‚îÄ‚îÄ test_health.py
‚îî‚îÄ‚îÄ (more test modules)
```

---

## Installation & Testing

### Requirements

- Python 3.8+
- opencv-python
- sounddevice, soundfile
- pyttsx3 (text-to-speech)
- websockets
- PyYAML
- (optional) Flask, Flask-SQLAlchemy for Operator UI

### Install

```bash
pip install -r requirements.txt
```

### Run Tests

```bash
pytest tests/ -v
```

### Platform Notes

- **Windows**: May require restarting after OpenCV/sounddevice install
- **macOS**: Requires microphone permissions
- **Linux**: May need ALSA/PulseAudio configuration for audio

---

## API Reference

The engine exposes a WebSocket JSON-RPC interface on `ws://127.0.0.1:8765`.

### List Tools

```json
{"method": "list_tools"}
```

Returns all available tools with schemas.

### Call Tool

```json
{
  "method": "call_tool",
  "params": {
    "agent_id": "my-agent",
    "call_id": "call-001",
    "tool": "capture_frame",
    "args": {}
  }
}
```

### Get History

```json
{"method": "get_history", "params": {"limit": 10}}
```

Returns recent events from world model.

### Health Check

```json
{"method": "ping"}
```

Returns engine status and version.

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Engine won't start | Check port 8765 is free: `netstat -an \| findstr :8765` (Windows), `lsof -i :8765` (macOS/Linux) |
| Camera not detected | Run `list_cameras()` to verify device availability; check permissions |
| Audio not recorded | Run `list_audio_devices()`; check microphone permissions |
| Simulated mode not working | Set `ANSE_SIMULATE=1` environment variable before starting |
| WebSocket connection refused | Ensure engine is running and firewall allows 8765 |
| Plugin not loading | Check plugin YAML syntax; restart engine after adding plugin |

---

## Performance

| Metric | Value |
|--------|-------|
| WebSocket latency | < 1 ms (local) |
| Tool execution | Hardware-dependent |
| Event log write | < 1 ms (JSONL append) |
| Memory footprint | ~50-100 MB (engine + tools) |
| Concurrent agents | Designed for multi-agent support; tested with 3+ agents per engine |

---

## üõ£Ô∏è Roadmap

### Current (February 2026)
- ‚úÖ Event-driven nervous system architecture
- ‚úÖ Plugin system with categorized organization
- ‚úÖ Comprehensive documentation suite (6 guides)
- üîÑ Dashboard rewrite (WebSocket events, remove polling)
- üîÑ Example agents (structure in place, code coming)

### Next (March 2026)
- Complete dashboard rewrite with event listeners
- Full tutorial examples in `examples/` folder
- Performance benchmarking and optimization
- Extended plugin library (more sensor/actuator templates)

### Future (Q2 2026)
- Network tools (HTTP, ping, DNS)
- Filesystem tools (safe sandboxed access)
- Browser automation tools
- Real-world sensor integrations
- Cloud deployment guides

See [docs/ROADMAP.md](docs/ROADMAP.md) for detailed development plan.

---

## Development Status

**Phase 1 ‚úÖ** ‚Äî Core engine, event-driven architecture, plugin system, audit logging  
**Phase 2 ‚úÖ** ‚Äî Multi-agent isolation, safety & permissions, comprehensive documentation  
**Phase 3 üîÑ** ‚Äî Dashboard rewrite, example agents, extended tools (in progress)  
**Phase 4 ‚è≥** ‚Äî Network tools, filesystem tools, browser automation (coming next)

---

## Extending ANSE

### Add a Tool

```python
# Create tool in anse/tools/my_tools.py
async def my_tool(param: str) -> dict:
    """Description of what this tool does."""
    # Use asyncio.to_thread() for blocking I/O
    result = await asyncio.to_thread(blocking_operation, param)
    return {"status": "success", "data": result}

# Register in engine_core.py
self.tools.register(
    "my_tool",
    my_tool,
    schema={"type": "object", "properties": {...}},
    description="What this tool does",
    sensitivity="public"
)
```

See [docs/API.md](docs/API.md) for complete examples.

---

## üìñ Full Documentation Index

**See [Documentation Map](#-documentation-map) above for when to use each guide.**

Complete reference:
- **[Quick Start Guide](docs/QUICKSTART.md)** ‚Äî Install, run demo, verify setup
- **[Event-Driven Architecture](docs/EVENT_DRIVEN_ARCHITECTURE.md)** ‚Äî Core nervous system model (complete)
- **[Event-Driven Cheat Sheet](docs/EVENT_DRIVEN_CHEATSHEET.md)** ‚Äî Quick reference, copy-paste patterns
- **[Migration from Polling to Events](docs/MIGRATION_POLLING_TO_EVENTS.md)** ‚Äî Convert existing code (with examples)
- **[Implementation Checklist](docs/IMPLEMENTATION_CHECKLIST.md)** ‚Äî Structured 6-phase guide (10-20 days)
- **[Troubleshooting Event-Driven Issues](docs/TROUBLESHOOTING_EVENT_DRIVEN.md)** ‚Äî Problem solving & debugging
- **[Architecture & Design](docs/DESIGN.md)** ‚Äî Engine internals, component interactions
- **[API Reference](docs/API.md)** ‚Äî Tool schemas, method signatures, JSON-RPC interface
- **[Plugin Development](docs/PLUGINS.md)** ‚Äî Building sensors, actuators, cognitive plugins
- **[Roadmap](docs/ROADMAP.md)** ‚Äî Future features and development timeline
- **[Installation Guide](docs/INSTALLATION.md)** ‚Äî Detailed setup for each platform
- **[Autonomous Agent Demo](docs/AUTONOMOUS_AGENT_UPDATE.md)** ‚Äî How the working example works internally

---

## Contributing

Contributions welcome! See [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md) for:
- Reporting issues
- Proposing features
- Submitting pull requests

---

## License

ANSE is released under the MIT License. See [LICENSE](LICENSE) for details.

---

## Citation

If you use ANSE in research, please cite:

```bibtex
@software{anse2026,
  title={ANSE: Agent Nervous System Engine},
  author={13thrule},
  year={2026},
  url={https://github.com/13thrule/ANSE-Agent-Nervous-System-Engine}
}
```

---

**Status:** Early-stage but stable ‚Äî solid foundation, active development  
**Python:** 3.8+ | **License:** MIT | **Platform:** Windows, macOS, Linux  
**Last Updated:** February 2026
